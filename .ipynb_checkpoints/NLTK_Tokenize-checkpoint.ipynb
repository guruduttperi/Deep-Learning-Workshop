{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>NLTK TOKENIZE</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/Perichetla/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Come', 'with', 'me', 'if', 'you', 'want', 'to', 'live', '!']\n"
     ]
    }
   ],
   "source": [
    "s1 = \"Come with me if you want to live!\"\n",
    "print(word_tokenize(s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Come with me if you want to live.', 'Hasta la Vista, Baby!', 'I am a model T-800 Cybernetic Organism...']\n"
     ]
    }
   ],
   "source": [
    "s2 = \"Come with me if you want to live. Hasta la Vista, Baby! I am a model T-800 Cybernetic Organism...\"\n",
    "print(sent_tokenize(s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1>STOPWORDS</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-53-88cbdb3d4531>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-53-88cbdb3d4531>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    if not s in s2\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords as sw\n",
    "\n",
    "s2 = \"Come with me if you want to live. Hasta la Vista, Baby! I am a model T-800 Cybernetic Organism...\"\n",
    "sw = [\"live\",\"model\"]\n",
    "filter = [s for s in s2 if not s in sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'o', 'm', 'e', ' ', 'w', 'i', 't', 'h', ' ', 'm', 'e', ' ', 'i', 'f', ' ', 'y', 'o', 'u', ' ', 'w', 'a', 'n', 't', ' ', 't', 'o', ' ', 'l', 'i', 'v', 'e', '.', ' ', 'H', 'a', 's', 't', 'a', ' ', 'l', 'a', ' ', 'V', 'i', 's', 't', 'a', ',', ' ', 'B', 'a', 'b', 'y', '!', ' ', 'I', ' ', 'a', 'm', ' ', 'a', ' ', 'm', 'o', 'd', 'e', 'l', ' ', 'T', '-', '8', '0', '0', ' ', 'C', 'y', 'b', 'e', 'r', 'n', 'e', 't', 'i', 'c', ' ', 'O', 'r', 'g', 'a', 'n', 'i', 's', 'm', '.', '.', '.']\n"
     ]
    }
   ],
   "source": [
    "print(filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Parts of Speech </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"His grandfather's cat kicked the bucket after an excessive dose of catnip!\", 'It was an urban tragedy!']\n"
     ]
    }
   ],
   "source": [
    "s4 = \"His grandfather's cat kicked the bucket after an excessive dose of catnip! It was an urban tragedy!\"\n",
    "s5 = nltk.sent_tokenize(s4)\n",
    "print(s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Perichetla/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "His ---> PRP$\n",
      "grandfather ---> NN\n",
      "'s ---> POS\n",
      "cat ---> NN\n",
      "kicked ---> VBD\n",
      "the ---> DT\n",
      "bucket ---> NN\n",
      "after ---> IN\n",
      "an ---> DT\n",
      "excessive ---> JJ\n",
      "dose ---> NN\n",
      "of ---> IN\n",
      "catnip ---> NN\n",
      "! ---> .\n",
      "It ---> PRP\n",
      "was ---> VBD\n",
      "an ---> DT\n",
      "urban ---> JJ\n",
      "tragedy ---> NN\n",
      "! ---> .\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "for token in s5:\n",
    "    wt = nltk.word_tokenize(token)\n",
    "    for word,pos in nltk.pos_tag(wt):\n",
    "        print(word,'--->',pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
